{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import mobilenet_v3 \n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, GaussianNoise\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish:  19226\n",
      "No Fish:  15266\n"
     ]
    }
   ],
   "source": [
    "fish = len(os.listdir(\"AnadromSmall/Fish\"))\n",
    "noFish = len(os.listdir(\"AnadromSmall/NoFish\"))\n",
    "\n",
    "print(\"Fish: \", fish)\n",
    "print(\"No Fish: \", noFish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads a basemodel from MobileNet framework with pretrained weights from ImageNet, a general puprose dataset. \\\n",
    "\\\n",
    "The model does not include a top, because we will implement the last layer as binary classification \\\n",
    "\\\n",
    "Input shape is the image size and color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We freeze the model weights during training, this is because we imported a pretrained model that has already learned important features like edge detection, textures and shapes. Our model will only be learning and updating the dense layer (The layers we are tweaking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extracts the last layers from the base model to connect with our dense layers. \n",
    "GlobalAveragePooling2D converts the feature maps into a 1D vector by averaging the map.\n",
    "\n",
    "\\\n",
    "The base_model gives us a complicated output shape with a spatial grid(x, y) and feature maps (564 channels) <- example \\\n",
    "\\\n",
    "We need to make this into a single 1D vector, so we average the spatial features of each channel and put it in the vector. \\\n",
    "\\\n",
    "Then we create a dense layer with 128 neurons using relu activation to make it non linear, this means it takes all the channels from the base model output as input to the 128 neurons.\n",
    "\\ \n",
    "\\\n",
    "This is the layer our model tweakes and for the binary classification\n",
    "\\\n",
    "\\\n",
    "Lastly we create the output layer which only features one neuron and uses the sigmoid activation so the value is between 0 and 1 and represesnt the probability that the image contains a fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = GaussianNoise(0.1)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27594 images belonging to 2 classes.\n",
      "Found 6898 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-300:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 777, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 752, in pool_fn\n",
      "    pool = get_pool_class(True)(\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\joach\\.conda\\envs\\tf\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=30,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'AnadromSmall',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'AnadromSmall',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "863/863 [==============================] - 51s 56ms/step - loss: 0.2077 - accuracy: 0.9302 - val_loss: 1.8465 - val_accuracy: 0.6061\n",
      "Epoch 2/5\n",
      "863/863 [==============================] - 55s 63ms/step - loss: 0.0844 - accuracy: 0.9711 - val_loss: 1.9150 - val_accuracy: 0.6299\n",
      "Epoch 3/5\n",
      "863/863 [==============================] - 47s 55ms/step - loss: 0.0570 - accuracy: 0.9803 - val_loss: 2.4087 - val_accuracy: 0.6239\n",
      "Epoch 4/5\n",
      "863/863 [==============================] - 50s 58ms/step - loss: 0.0416 - accuracy: 0.9849 - val_loss: 2.4728 - val_accuracy: 0.6102\n",
      "Epoch 5/5\n",
      "863/863 [==============================] - 46s 54ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 3.0461 - val_accuracy: 0.6155\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Lower LR for fine-tuning\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "model.fit(train_generator, epochs=5, validation_data=val_generator)\n",
    "\n",
    "\n",
    "model.save(\"mobilenetv3_fish_classifier1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
